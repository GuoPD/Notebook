&#8195;&#8195;在特征工程中，稀疏特征能更很好的表征数据，并且便于存储与分析，对于大数据集来说特别重要。因此，常会采用一些方法来使特征产生稀疏性。

----------


## 简单截断

&#8195;&#8195;一个比较简单粗暴的方式是，设置一个阈值，当某个维度的系数绝对值小于该阈值时，直接置为0，这就是所谓的简单截断法。
&#8195;&#8195;其权重更新方式为：

$$W^{(t+1)} = T_0(W^{(t+1)}-\eta^{(t)}G^{(t)},\theta)$$

&#8195;&#8195;其中，

$$ T_0(v_i,\theta)=\left\{
\begin{array}{rcl}
0       &      & {if\ |v_i|      <      \theta}\\
v_i     &      & {otherwise }\\
\end{array} \right. $$

&#8195;&#8195;公式中，$\theta$是个正数，$V$是向量。在实际应用中，往往会以k为窗口，每k步迭代进行一次截断。

----------

## 梯度截断法

&#8195;&#8195;简单截断过于粗暴，因此，可以采用更为柔和的方式进行两步截断。当某个维度小于一定值，又不特别小时，进行适量的减小，这样处理就温柔了许多。其权值更新过程如下：

$$W^{(t+1)} = T_1(W^{(t+1)}-\eta^{(t)}G^{(t)}, \eta^{(t)}\lambda^{(t)} ,\theta)$$

&#8195;&#8195;其中，

$$ T_1(v_i,\alpha,\theta)=\left\{
\begin{array}{c}
max(0,v_i-\alpha)   & {if\  v_i \in [0,\theta]}\\
min(0,v_i-\alpha)   & {if\ v_i \in [-\theta,0]}\\
v_i                 & {otherwise}
\end{array} \right. $$

&#8195;&#8195;从公式可以看出，当$|v_i| \in [\alpha,\theta]$时，$v_i$都是向0的取值靠近了一下，而不是直接生硬的变成0，因此，可以看出，$\lambda$和$\theta$共同决定了截断的区域大小。在实际应用时，窗口仍设置为$k$，当$\frac{t}{k}$不为整数时，$\lambda^{(t)}=0$，当$\frac{t}{k}$为整数时，$\lambda^{(t)}=k\lambda$。随着算法的迭代进行，截断区域会越来越大。
